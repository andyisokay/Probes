{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/andy_lee/EvalLatentKnowledge/Probes')\n",
    "import Generate_Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from Generate_Embeddings import init_model, load_data, process_batch, save_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json fetched...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"/data/andy_lee/EvalLatentKnowledge/Probes/config.json\") as config_file:\n",
    "        print('config.json fetched...')\n",
    "        config_parameters = json.load(config_file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Configuration file not found. Please ensure the file exists and the path is correct.\")\n",
    "    logging.error(\"Configuration file not found. Please ensure the file exists and the path is correct.\")\n",
    "except PermissionError:\n",
    "    print(\"Permission denied. Please check your file permissions.\")\n",
    "    logging.error(\"Permission denied. Please check your file permissions.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Configuration file is not valid JSON. Please check the file's contents.\")\n",
    "    logging.error(\"Configuration file is not valid JSON. Please check the file's contents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the language model to use: '6.7b', '2.7b', '1.3b', '350m'\"\n",
    "model_name = config_parameters[\"model\"]\n",
    "should_remove_period = config_parameters[\"remove_period\"]\n",
    "layers_to_process = config_parameters[\"layers_to_use\"]\n",
    "dataset_names = config_parameters[\"list_of_datasets\"]\n",
    "true_false = config_parameters[\"true_false\"]\n",
    "BATCH_SIZE = config_parameters[\"batch_size\"]\n",
    "# dataset_path = Path(config_parameters[\"dataset_path\"])\n",
    "dataset_path = Path('/data/andy_lee/EvalLatentKnowledge/Probes/datasets') \n",
    "output_path = Path('/data/andy_lee/EvalLatentKnowledge/Probes/processed_dataset_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 6.7b\n",
      "should_remove_period: True\n",
      "layers_to_process: [-1, -4, -6, -8]\n",
      "dataset_names: ['facts', 'elements']\n",
      "true_false: True\n",
      "BATCH_SIZE: 32\n",
      "dataset_path: /data/andy_lee/EvalLatentKnowledge/Probes/datasets\n",
      "output_path: /data/andy_lee/EvalLatentKnowledge/Probes/processed_dataset_path\n"
     ]
    }
   ],
   "source": [
    "print(f\"model: {model_name}\")\n",
    "print(f\"should_remove_period: {should_remove_period}\")\n",
    "print(f\"layers_to_process: {layers_to_process}\")\n",
    "print(f\"dataset_names: {dataset_names}\")\n",
    "print(f\"true_false: {true_false}\")\n",
    "print(f\"BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"dataset_path: {dataset_path}\")\n",
    "print(f\"output_path: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e4518a4ecf42499f863e8698dc538b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e706c1fe3d742198fda6afac1df83f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/41.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a57bb5ae9da44a59baf28bbd7242487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde19c8db0704335ae2e4353ab23da51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368a4d0ac0b94d9b959f4aee30ded9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10205af8145946e79362fd1658eb2e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fecc81aeeed40db8b5028b0f1c9d8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382f0913afc047499bfd3668c92df368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0758c87fc6444e20933be154ca56382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb78c1a2ef4066a9db573c05684165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdcce56ebf8457aaceca0eda86b6765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_output_per_layer: Dict[int, pd.DataFrame] = {}\n",
    "\n",
    "model, tokenizer = init_model(model_name)\n",
    "if model is None or tokenizer is None:\n",
    "    print(\"Model or tokenizer initialization failed.\")\n",
    "    logging.error(\"Model or tokenizer initialization failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing batches in facts: 100%|██████████| 20/20 [05:29<00:00, 16.45s/it]\n",
      "Processing batches in elements: 100%|██████████| 30/30 [08:00<00:00, 16.00s/it]\n",
      "Processing datasets: 100%|██████████| 2/2 [13:47<00:00, 413.98s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loads configuration parameters, initializes the model and tokenizer, and processes datasets.\n",
    "\n",
    "Configuration parameters are loaded from a JSON file named \"BenConfigMultiLayer.json\". \n",
    "These parameters specify the model to use, whether to remove periods from the end of sentences, \n",
    "which layers of the model to use for generating embeddings, the list of datasets to process, \n",
    "and the paths to the input datasets and output location.\n",
    "\n",
    "The script processes each dataset according to the configuration parameters, generates embeddings for \n",
    "each sentence in the dataset using the specified model and layers, and saves the processed data to a CSV file. \n",
    "If processing a dataset or saving the data fails, the script logs an error message and continues with the next dataset.\n",
    "\"\"\"\n",
    "\n",
    "for dataset_name in tqdm(dataset_names, desc=\"Processing datasets\"):\n",
    "    # Increase the threshold parameter to a large number\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "    dataset = load_data(dataset_path, dataset_name, true_false=true_false)\n",
    "    if dataset is None:\n",
    "        continue\n",
    "\n",
    "    num_batches = len(dataset) // BATCH_SIZE + (len(dataset) % BATCH_SIZE != 0)\n",
    "\n",
    "    for layer in layers_to_process:\n",
    "        model_output_per_layer[layer] = dataset.copy()\n",
    "        model_output_per_layer[layer]['embeddings'] = pd.Series(dtype='object')\n",
    "\n",
    "    for batch_num in tqdm(range(num_batches), desc=f\"Processing batches in {dataset_name}\"):\n",
    "        start_idx = batch_num * BATCH_SIZE\n",
    "        actual_batch_size = min(BATCH_SIZE, len(dataset) - start_idx)\n",
    "        end_idx = start_idx + actual_batch_size\n",
    "        batch = dataset.iloc[start_idx:end_idx]\n",
    "        batch_prompts = batch['statement'].tolist()\n",
    "        batch_embeddings = process_batch(batch_prompts, model, tokenizer, layers_to_process, should_remove_period)\n",
    "\n",
    "        for layer in layers_to_process:\n",
    "            for i, idx in enumerate(range(start_idx, end_idx)):\n",
    "                model_output_per_layer[layer].at[idx, 'embeddings'] = batch_embeddings[layer][i]\n",
    "\n",
    "        if batch_num % 10 == 0:\n",
    "            logging.info(f\"Processing batch {batch_num}\")\n",
    "\n",
    "    for layer in layers_to_process:\n",
    "        save_data(model_output_per_layer[layer], output_path, dataset_name, model_name, layer, should_remove_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-influence",
   "language": "python",
   "name": "influence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
